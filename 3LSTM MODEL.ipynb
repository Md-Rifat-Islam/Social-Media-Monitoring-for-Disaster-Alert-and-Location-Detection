{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6E-UA-_gU0Bd"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from google.colab import drive\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AkKa2Dn43HV"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to access dataset and save the model\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyFxppq1WpuL"
   },
   "outputs": [],
   "source": [
    "# Load dataset from Google Drive\n",
    "path = \"/content/drive/MyDrive/ML_Project/tweets.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnmOeOOrXgIs"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the 'text' column\n",
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQE-ATpiXjRE"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()  # Initialize the tokenizer\n",
    "tokenizer.fit_on_texts(df['text'])  # Learn word indices from the text data\n",
    "total_words = len(tokenizer.word_index) + 1  # Total number of unique words (vocabulary size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfObV9-oXoFH"
   },
   "outputs": [],
   "source": [
    "# Convert text into sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])  # Encode the text as integer sequences\n",
    "padded_sequences = pad_sequences(sequences)  # Pad sequences to ensure uniform length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKCfQT6rXzvj"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences, df['target'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkwwyEYkX2qr"
   },
   "outputs": [],
   "source": [
    "# Define the LSTM-based neural network model\n",
    "embedding_dim = 50  # Dimension of the word embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=embedding_dim, input_length=padded_sequences.shape[1]))\n",
    "model.add(LSTM(100))  # Add an LSTM layer with 100 units\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeGK9wM1Zjst"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98323,
     "status": "ok",
     "timestamp": 1701183453759,
     "user": {
      "displayName": "Tausiful Haque",
      "userId": "11647906136315291745"
     },
     "user_tz": -360
    },
    "id": "dAWcSptxbew9",
    "outputId": "d2e9f63f-34b3-4401-e20d-f721c62f68a7"
   },
   "outputs": [],
   "source": [
    "# Train the model for 5 epochs\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1701183684176,
     "user": {
      "displayName": "Tausiful Haque",
      "userId": "11647906136315291745"
     },
     "user_tz": -360
    },
    "id": "GA19eaTicuwG",
    "outputId": "43883b3b-3625-458e-9677-bf034b5fdef9"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1701184598753,
     "user": {
      "displayName": "Tausiful Haque",
      "userId": "11647906136315291745"
     },
     "user_tz": -360
    },
    "id": "yWRRLEoneLKQ",
    "outputId": "0253f1f7-720e-4912-f127-ef78514d53e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Test sentence: \"No cows today but our local factory is sadly still ablaze\" is a disaster.\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a single example\n",
    "test_sentence = [\"No cows today but our local factory is sadly still ablaze\"]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentence)  # Encode the test sentence\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=padded_sequences.shape[1])  # Pad the test sequence\n",
    "\n",
    "# Get predictions from the model\n",
    "predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Use a threshold to classify the sentence\n",
    "threshold = 0.5\n",
    "if predictions[0, 0] >= threshold:\n",
    "    print(f'Test sentence: \"{test_sentence[0]}\" is a disaster.')\n",
    "else:\n",
    "    print(f'Test sentence: \"{test_sentence[0]}\" is not a disaster.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8851,
     "status": "ok",
     "timestamp": 1701187114594,
     "user": {
      "displayName": "Tausiful Haque",
      "userId": "11647906136315291745"
     },
     "user_tz": -360
    },
    "id": "iS32z7VfpwOY",
    "outputId": "c0305176-2edf-490f-cd26-917fe8b71e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaster Locations: ['Florida']\n"
     ]
    }
   ],
   "source": [
    "# Extract locations from a sentence using spaCy\n",
    "test_sentence = \"There is a cyclone in Florida\"\n",
    "nlp = spacy.load('en_core_web_sm')  # Load the spaCy English language model\n",
    "doc = nlp(test_sentence)  # Process the sentence\n",
    "locations = [ent.text for ent in doc.ents if ent.label_ == 'GPE']  # Extract Geo-political Entities (GPE)\n",
    "print(\"Disaster Locations:\", locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbSc3cv6eNUd"
   },
   "outputs": [],
   "source": [
    "# Save the trained LSTM model using pickle\n",
    "with open('/content/drive/MyDrive/ML_Project/lstm.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
