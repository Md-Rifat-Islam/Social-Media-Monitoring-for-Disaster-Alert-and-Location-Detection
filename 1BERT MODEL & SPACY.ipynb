{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UsiRqSyv0eB"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importing libraries\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification  # For tokenization and sequence classification\n",
    "from sklearn.metrics import accuracy_score  # For evaluating model accuracy\n",
    "import pandas as pd  # For data manipulation\n",
    "import torch  # For PyTorch deep learning framework\n",
    "import spacy  # For NLP tasks like lemmatization and entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBl5n1RFv-ca"
   },
   "outputs": [],
   "source": [
    "# Defining the device to use GPU if available\n",
    "device = torch.device('cuda')  # Use GPU for faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1Pk2cUOERFI"
   },
   "outputs": [],
   "source": [
    "# Mounting Google Drive to access dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQvo5LL8wFKw"
   },
   "outputs": [],
   "source": [
    "# Reading the CSV dataset, selecting only relevant columns\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/ML_Project/tweets.csv\", usecols=['text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n82Egzx5wA58"
   },
   "outputs": [],
   "source": [
    "# Loading spaCy English model for NLP\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zewtO-awGKf"
   },
   "outputs": [],
   "source": [
    "# Lemmatizing and removing stop words from the text column\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([\n",
    "    token.lemma_ for token in nlp(x) if not token.is_stop and token.is_alpha\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHBdfe33wHTf"
   },
   "outputs": [],
   "source": [
    "# Initializing DistilBERT tokenizer and model for sequence classification\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tplLvLWPwIwq"
   },
   "outputs": [],
   "source": [
    "# Moving the model to the specified device (GPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqwUVUOQwNoS"
   },
   "outputs": [],
   "source": [
    "# Tokenizing the text data with padding, truncation, and max length\n",
    "inputs = tokenizer(\n",
    "    df['text'].tolist(), \n",
    "    return_tensors='pt', \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2ZgV5k6wOuw"
   },
   "outputs": [],
   "source": [
    "# Converting target labels to tensors\n",
    "labels = torch.tensor(df['target'].tolist())\n",
    "\n",
    "# Initializing the optimizer with a learning rate of 1e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAnMOrpYwQkC"
   },
   "outputs": [],
   "source": [
    "# Fine-tuning DistilBERT on the dataset\n",
    "for epoch in range(1):  # Running for one epoch\n",
    "    for i in range(len(inputs['input_ids'])):\n",
    "        # Extracting input IDs and attention masks for each sample\n",
    "        input_id = inputs['input_ids'][i].to(device)\n",
    "        attention_mask = inputs['attention_mask'][i].to(device)\n",
    "        label = labels[i].to(device)\n",
    "        \n",
    "        # Zeroing gradients for each step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_id.unsqueeze(0),  # Add batch dimension\n",
    "            attention_mask=attention_mask.unsqueeze(0),\n",
    "            labels=label.unsqueeze(0)\n",
    "        )\n",
    "        loss = outputs.loss  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "        \n",
    "        # Logging progress every 100 samples\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Processed {i+1} out of {len(inputs[\"input_ids\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y85idP5pw1OU"
   },
   "outputs": [],
   "source": [
    "# Setting the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing inference on the dataset to make predictions\n",
    "predictions = []\n",
    "for i in range(len(inputs['input_ids'])):\n",
    "    input_id = inputs['input_ids'][i].to(device)\n",
    "    attention_mask = inputs['attention_mask'][i].to(device)\n",
    "    \n",
    "    # Forward pass without gradient computation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_id.unsqueeze(0),\n",
    "            attention_mask=attention_mask.unsqueeze(0)\n",
    "        )\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1)  # Predicting the class\n",
    "    predictions.append(prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1701172922526,
     "user": {
      "displayName": "Nurshat Fateh Ali",
      "userId": "01142595475851024591"
     },
     "user_tz": -360
    },
    "id": "dcpjadPdzQ9e",
    "outputId": "2694f41c-c895-48a2-e25b-fe6d1de2aed8"
   },
   "outputs": [],
   "source": [
    "# Calculating the accuracy of predictions\n",
    "accuracy = accuracy_score(labels.tolist(), predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1701173996088,
     "user": {
      "displayName": "Nurshat Fateh Ali",
      "userId": "01142595475851024591"
     },
     "user_tz": -360
    },
    "id": "E4NrXEJHzStI",
    "outputId": "571c4f22-6040-4ef0-8da2-81de19c10a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: \"There is a cyclone in Florida\" is a disaster\n"
     ]
    }
   ],
   "source": [
    "# Testing a single sentence\n",
    "test_sentence = \"There is a cyclone in Florida\"\n",
    "test_input = tokenizer(\n",
    "    test_sentence, \n",
    "    return_tensors='pt', \n",
    "    truncation=True, \n",
    "    padding=True\n",
    ")\n",
    "test_input = {k: v.to(device) for k, v in test_input.items()}  # Moving data to GPU\n",
    "test_output = model(**test_input)  # Model inference\n",
    "test_prediction = torch.argmax(test_output.logits, dim=-1)\n",
    "print(f'Test sentence: \\\"{test_sentence}\\\" is {\"a disaster\" if test_prediction.item() else \"not a disaster\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iINSpOelzXiy"
   },
   "outputs": [],
   "source": [
    "# Saving the model using pickle\n",
    "import pickle\n",
    "with open('/content/drive/MyDrive/ML_Project/mlmodel.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2077,
     "status": "ok",
     "timestamp": 1701174000798,
     "user": {
      "displayName": "Nurshat Fateh Ali",
      "userId": "01142595475851024591"
     },
     "user_tz": -360
    },
    "id": "YWupbYG-1q9_",
    "outputId": "d2bea78b-b029-4bd0-b831-b726f2c642b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaster Locations: ['Florida']\n"
     ]
    }
   ],
   "source": [
    "# Performing NER on a test sentence to extract locations\n",
    "test_sentence = \"There is a cyclone in Florida\"\n",
    "doc = nlp(test_sentence)  # Processing sentence with spaCy\n",
    "locations = [ent.text for ent in doc.ents if ent.label_ == 'GPE']  # Extracting named entities labeled as GPE (Geo-political entity)\n",
    "print(\"Disaster Locations:\", locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1701174018006,
     "user": {
      "displayName": "Nurshat Fateh Ali",
      "userId": "01142595475851024591"
     },
     "user_tz": -360
    },
    "id": "nj2Y9an22I1E",
    "outputId": "f3f08f6e-d237-426b-c64d-0d68eb4c798c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: \"My life is a cyclone\" is not a disaster\n"
     ]
    }
   ],
   "source": [
    "# Testing another sentence\n",
    "test_sentence = \"My life is a cyclone\"\n",
    "test_input = tokenizer(\n",
    "    test_sentence, \n",
    "    return_tensors='pt', \n",
    "    truncation=True, \n",
    "    padding=True\n",
    ")\n",
    "test_input = {k: v.to(device) for k, v in test_input.items()}\n",
    "test_output = model(**test_input)\n",
    "test_prediction = torch.argmax(test_output.logits, dim=-1)\n",
    "print(f'Test sentence: \\\"{test_sentence}\\\" is {\"a disaster\" if test_prediction.item() else \"not a disaster\"}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
